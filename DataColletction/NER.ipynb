{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"rel_info.json\",)\n",
    "\n",
    "info = json.load(f)\n",
    "f = open(\"dev.json\",)\n",
    "d = json.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#>>> d[0].keys()\n",
    "#[u'labels', u'sents', u'vertexSet', u'title']\n",
    "\n",
    "indexForData = 1\n",
    "AllSents = []\n",
    "\n",
    "for i,sent in enumerate(d[indexForData]['sents']):\n",
    "    print(i,' '.join(sent))\n",
    "    AllSents.append(' '.join(sent))\n",
    "\n",
    "for label in d[indexForData]['labels']:\n",
    "    if d[indexForData]['vertexSet'][label['h']][0]['type'] != \"ORG\" and d[indexForData]['vertexSet'][label['t']][0]['type'] != \"ORG\":\n",
    "        print(d[indexForData]['vertexSet'][label['h']])\n",
    "        print(d[indexForData]['vertexSet'][label['t']])\n",
    "        print(AllSents[d[indexForData]['vertexSet'][label['h']][0]['sent_id']])\n",
    "        print(AllSents[d[indexForData]['vertexSet'][label['t']][0]['sent_id']])\n",
    "        print(info[label['r']])\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexForData = 1\n",
    "abelssDict = {}\n",
    "for label in d[indexForData]['labels']:\n",
    "    if d[indexForData]['vertexSet'][label['h']][0]['type'] not in labelssDict:\n",
    "        labelssDict[d[indexForData]['vertexSet'][label['h']][0]['type']] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import json\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def transferType(_type):\n",
    "    if _type == \"ORG\":\n",
    "        return [\"Organization\"]\n",
    "    elif _type == \"LOC\":\n",
    "        return [\"Location\"]\n",
    "    elif _type == \"TIME\":\n",
    "        return [\"Time\"]\n",
    "    elif _type == \"PER\":\n",
    "        return [\"Person\"]\n",
    "    elif _type == \"NUM\":\n",
    "        return [\"Number\"]\n",
    "    elif _type == \"MISC\":\n",
    "        return [\"Misc\"]\n",
    "\n",
    "# labelssDict = set()\n",
    "count = 0\n",
    "AllTasks = []\n",
    "for vertex in d:\n",
    "    AllSents = []\n",
    "    if count > 100:\n",
    "        break\n",
    "    # else:\n",
    "        # print(count)\n",
    "    # print(len(vertex['labels']))\n",
    "    if len(vertex['labels']) <= 3:\n",
    "        count = count + 1\n",
    "        for i,sent in enumerate(vertex['sents']):\n",
    "            # print(i,' '.join(sent))\n",
    "            AllSents.append(' '.join(sent)) \n",
    "        para = ' '.join(AllSents) \n",
    "        para = para.replace(\" .\", \".\")\n",
    "        # print(para)\n",
    "        task = {}\n",
    "        task['text'] = para\n",
    "        task['layout_id'] = 2\n",
    "        task['groundTruth'] = \" \"\n",
    "        task['format_type'] = 1\n",
    "        task['batch_id'] = 5\n",
    "        task['description'] = \" \"\n",
    "        task['id'] = count\n",
    "\n",
    "        comData = {}\n",
    "        comData['lead_time'] = 3.821\n",
    "        comData['result'] = []\n",
    "        comData['user'] = 0\n",
    "        # completion['created_at'] = 1616101190\n",
    "\n",
    "        foundLabesl = {}\n",
    "        foundRelations = {}\n",
    "\n",
    "        for label in vertex['labels']:\n",
    "            headent = vertex['vertexSet'][label['h']][0]\n",
    "            tailent = vertex['vertexSet'][label['t']][0]\n",
    "            # print(headent, tailent, label, info[label['r']])\n",
    "            # print(\"\\n\")\n",
    "            val1 = {}\n",
    "            if headent['name'] not in foundLabesl:                \n",
    "                val1['value'] = {}\n",
    "                val1['value']['start'] = para.find(headent['name'])\n",
    "                if val1['value']['start'] == -1:\n",
    "                    continue\n",
    "                val1['value']['end'] = val1['value']['start'] + len(headent['name'])\n",
    "                val1['value']['text'] = headent['name']\n",
    "                val1['value']['labels'] = transferType(headent['type'])\n",
    "                val1['id'] = id_generator(7)\n",
    "                val1['from_name'] = \"label\"\n",
    "                val1['to_name'] = \"text\"\n",
    "                val1['type'] = \"labels\"\n",
    "                comData['result'].append(val1)\n",
    "                foundLabesl[headent['name']] = val1['id']\n",
    "            else:\n",
    "                val1['id'] = foundLabesl[headent['name']]\n",
    "\n",
    "            val2 = {}\n",
    "            if tailent['name'] not in foundLabesl:\n",
    "                val2['value'] = {}\n",
    "                val2['value']['start'] = para.find(tailent['name'])\n",
    "                if val2['value']['start'] == -1:\n",
    "                    continue\n",
    "                val2['value']['end'] = val2['value']['start'] + len(tailent['name'])\n",
    "                val2['value']['text'] = tailent['name']\n",
    "                val2['value']['labels'] = transferType(tailent['type'])\n",
    "                val2['id'] = id_generator(7)\n",
    "                val2['from_name'] = \"label\"\n",
    "                val2['to_name'] = \"text\"\n",
    "                val2['type'] = \"labels\"\n",
    "                comData['result'].append(val2)\n",
    "                foundLabesl[tailent['name']] = val2['id']\n",
    "            else:\n",
    "                val2['id'] = foundLabesl[tailent['name']]\n",
    "\n",
    "            val3 = {}\n",
    "            if (val1['id'] in foundRelations and val2['id'] in foundRelations[val1['id']]) or (val2['id'] in foundRelations and val1['id'] in foundRelations[val2['id']]):\n",
    "                continue\n",
    "            else:\n",
    "                foundRelations[val1['id']] = val2['id']\n",
    "                foundRelations[val2['id']] = val1['id'] \n",
    "                val3['labels'] = [info[label['r']]]\n",
    "                val3['direction'] = \"bi\"\n",
    "                val3['from_id'] = val1['id']\n",
    "                val3['to_id'] = val2['id']\n",
    "                val3['type'] = \"relation\"\n",
    "                print(val3)\n",
    "                comData['result'].append(val3)\n",
    "                \n",
    "        completion = {}\n",
    "        completion['task_id'] =count\n",
    "        completion['user_id'] = 0\n",
    "        completion['data'] = json.dumps(comData)\n",
    "        completion['completed_at'] = 1616101190\n",
    "        completion['batch_id'] = 5\n",
    "        completion['was_skipped'] = 0\n",
    "        task['completion'] =  completion\n",
    "        AllTasks.append(task)   \n",
    "        # break\n",
    "todump = {}\n",
    "todump[\"tasks\"] = AllTasks\n",
    "# print(json.dumps(todump))\n",
    "with open('RETaskDaataWith1label.json', 'w') as outfile:\n",
    "    json.dump(todump, outfile)\n",
    "print(count, \"Done\")\n",
    "# print(completion)"
   ]
  },
  {
   "source": [
    "for i in labelssDict:\n",
    "    print(i)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "import string\n",
    "import random\n",
    "import json\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def transferType(_type):\n",
    "    if _type == \"ORG\":\n",
    "        return [\"Organization\"]\n",
    "    elif _type == \"LOC\":\n",
    "        return [\"Location\"]\n",
    "    elif _type == \"TIME\":\n",
    "        return [\"Time\"]\n",
    "    elif _type == \"PER\":\n",
    "        return [\"Person\"]\n",
    "    elif _type == \"NUM\":\n",
    "        return [\"Number\"]\n",
    "    elif _type == \"MISC\":\n",
    "        return [\"Misc\"]\n",
    "\n",
    "# labelssDict = set()\n",
    "count = 0\n",
    "AllTasks = []\n",
    "for vertex in d:\n",
    "    AllSents = []\n",
    "    if count < 100:\n",
    "        count = count + 1\n",
    "        continue\n",
    "    if count > 200:\n",
    "        break\n",
    "    # else:\n",
    "        # print(count)\n",
    "    # print(len(vertex['labels']))\n",
    "    # if len(vertex['labels']) <= 3:\n",
    "    for i,sent in enumerate(vertex['sents']):\n",
    "        # print(i,' '.join(sent))\n",
    "        AllSents.append(' '.join(sent)) \n",
    "    para = ' '.join(AllSents) \n",
    "    para = para.replace(\" .\", \".\")\n",
    "    # print(para)\n",
    "    task = {}\n",
    "    task['text'] = para\n",
    "    task['layout_id'] = 2\n",
    "    task['groundTruth'] = \" \"\n",
    "    task['format_type'] = 1\n",
    "    task['batch_id'] = 5\n",
    "    task['description'] = \" \"\n",
    "    task['id'] = count\n",
    "\n",
    "    comData = {}\n",
    "    comData['lead_time'] = 3.821\n",
    "    comData['result'] = []\n",
    "    comData['user'] = 0\n",
    "    # completion['created_at'] = 1616101190\n",
    "\n",
    "    foundLabesl = {}\n",
    "    foundRelations = {}\n",
    "\n",
    "    for label in vertex['labels']:\n",
    "        headent = vertex['vertexSet'][label['h']][0]\n",
    "        tailent = vertex['vertexSet'][label['t']][0]\n",
    "        # print(headent, tailent, label, info[label['r']])\n",
    "        # print(\"\\n\")\n",
    "        val1 = {}\n",
    "        if headent['name'] not in foundLabesl:                \n",
    "            val1['value'] = {}\n",
    "            val1['value']['start'] = para.find(headent['name'])\n",
    "            if val1['value']['start'] == -1:\n",
    "                continue\n",
    "            val1['value']['end'] = val1['value']['start'] + len(headent['name'])\n",
    "            val1['value']['text'] = headent['name']\n",
    "            val1['value']['labels'] = transferType(headent['type'])\n",
    "            val1['id'] = id_generator(7)\n",
    "            val1['from_name'] = \"label\"\n",
    "            val1['to_name'] = \"text\"\n",
    "            val1['type'] = \"labels\"\n",
    "            comData['result'].append(val1)\n",
    "            foundLabesl[headent['name']] = val1['id']\n",
    "        else:\n",
    "            val1['id'] = foundLabesl[headent['name']]\n",
    "\n",
    "        val2 = {}\n",
    "        if tailent['name'] not in foundLabesl:\n",
    "            val2['value'] = {}\n",
    "            val2['value']['start'] = para.find(tailent['name'])\n",
    "            if val2['value']['start'] == -1:\n",
    "                continue\n",
    "            val2['value']['end'] = val2['value']['start'] + len(tailent['name'])\n",
    "            val2['value']['text'] = tailent['name']\n",
    "            val2['value']['labels'] = transferType(tailent['type'])\n",
    "            val2['id'] = id_generator(7)\n",
    "            val2['from_name'] = \"label\"\n",
    "            val2['to_name'] = \"text\"\n",
    "            val2['type'] = \"labels\"\n",
    "            comData['result'].append(val2)\n",
    "            foundLabesl[tailent['name']] = val2['id']\n",
    "        else:\n",
    "            val2['id'] = foundLabesl[tailent['name']]\n",
    "\n",
    "        val3 = {}\n",
    "        if (val1['id'] in foundRelations and val2['id'] in foundRelations[val1['id']]) or (val2['id'] in foundRelations and val1['id'] in foundRelations[val2['id']]):\n",
    "            continue\n",
    "        else:\n",
    "            foundRelations[val1['id']] = val2['id']\n",
    "            foundRelations[val2['id']] = val1['id'] \n",
    "            val3['labels'] = [info[label['r']]]\n",
    "            val3['direction'] = \"bi\"\n",
    "            val3['from_id'] = val1['id']\n",
    "            val3['to_id'] = val2['id']\n",
    "            val3['type'] = \"relation\"\n",
    "            print(val3)\n",
    "            comData['result'].append(val3)\n",
    "            break\n",
    "            \n",
    "    completion = {}\n",
    "    completion['task_id'] =count\n",
    "    completion['user_id'] = 0\n",
    "    completion['data'] = json.dumps(comData)\n",
    "    completion['completed_at'] = 1616101190\n",
    "    completion['batch_id'] = 5\n",
    "    completion['was_skipped'] = 0\n",
    "    task['completion'] =  completion\n",
    "    count = count + 1\n",
    "    AllTasks.append(task)   \n",
    "        # break\n",
    "todump = {}\n",
    "todump[\"tasks\"] = AllTasks\n",
    "# print(json.dumps(todump))\n",
    "with open('Only1Relations.json', 'w') as outfile:\n",
    "    json.dump(todump, outfile)\n",
    "print(count, \"Done\")\n",
    "# print(completion)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import json\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "notFound = 0\n",
    "def transferType(_type):\n",
    "    if _type == \"ORG\":\n",
    "        return [\"Organization\"]\n",
    "    elif _type == \"LOC\":\n",
    "        return [\"Location\"]\n",
    "    elif _type == \"TIME\":\n",
    "        return [\"Time\"]\n",
    "    elif _type == \"PER\":\n",
    "        return [\"Person\"]\n",
    "    elif _type == \"NUM\":\n",
    "        return [\"Number\"]\n",
    "    elif _type == \"MISC\":\n",
    "        return [\"Misc\"]\n",
    "\n",
    "# labelssDict = set()\n",
    "count = 0\n",
    "AllTasks = []\n",
    "for vertex in d:\n",
    "    AllSents = []\n",
    "    if count < 200:\n",
    "        count = count + 1\n",
    "        continue\n",
    "    if count > 300:\n",
    "        break\n",
    "    # else:\n",
    "        # print(count)\n",
    "    # print(len(vertex['labels']))\n",
    "    # if len(vertex['labels']) <= 3:\n",
    "    for i,sent in enumerate(vertex['sents']):\n",
    "        # print(i,' '.join(sent))\n",
    "        AllSents.append(' '.join(sent)) \n",
    "    if len(AllSents) > 10 or len(AllSents) < 3:\n",
    "        continue\n",
    "    para = ' '.join(AllSents) \n",
    "    para = para.replace(\" .\", \".\")\n",
    "    para = para.replace(\" ,\", \",\")\n",
    "    para = para.replace(\" - \", \"-\")\n",
    "    para = para.replace(\" -\", \"-\")\n",
    "    para = para.replace(\"- \", \"-\")\n",
    "    para = para.replace(\" – \", \"–\")\n",
    "    para = para.replace(\" –\", \"–\")\n",
    "    para = para.replace(\"– \", \"–\")\n",
    "    para = para.replace(\" '\", \"'\")\n",
    "    para = para.replace(\" n't\", \"n't\")\n",
    "    para = para.replace(\" 're\", \"'re\")\n",
    "    para = para.replace(\"( \", \"(\")\n",
    "    para = para.replace(\" )\", \")\")\n",
    "    para = para.replace('\" ', '\"')\n",
    "    para = para.replace(' \"', '\"')\n",
    "    para = para.replace(' ;', ';')\n",
    "    para = para.replace(' :', ':')\n",
    "\n",
    "    # print(para)\n",
    "    task = {}\n",
    "    task['text'] = para\n",
    "    task['layout_id'] = 2\n",
    "    task['groundTruth'] = \" \"\n",
    "    task['format_type'] = 1\n",
    "    task['batch_id'] = 1\n",
    "    task['description'] = \" \"\n",
    "    task['id'] = count\n",
    "\n",
    "    comData = {}\n",
    "    comData['lead_time'] = 3.821\n",
    "    comData['result'] = []\n",
    "    comData['user'] = 0\n",
    "    # completion['created_at'] = 1616101190\n",
    "\n",
    "    foundLabesl = {}\n",
    "    foundRelations = {}\n",
    "\n",
    "    for label in vertex['labels']:\n",
    "        headent = vertex['vertexSet'][label['h']][0]\n",
    "        tailent = vertex['vertexSet'][label['t']][0]\n",
    "        # print(headent, tailent, label, info[label['r']])\n",
    "        # print(\"\\n\")\n",
    "        val1 = {}\n",
    "        if headent['name'] not in foundLabesl:                \n",
    "            val1['value'] = {}\n",
    "            headent['name'] = headent['name'].replace(\" .\", \".\")\n",
    "            headent['name'] = headent['name'].replace(\" ,\", \",\")\n",
    "            headent['name'] = headent['name'].replace(\" – \", \"–\")\n",
    "            headent['name'] = tailent['name'].replace(\" -\", \"–\")\n",
    "            headent['name'] = tailent['name'].replace(\"– \", \"–\")\n",
    "            headent['name'] = headent['name'].replace(\" - \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" -\", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\"- \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" '\", \"'\")\n",
    "            headent['name'] = headent['name'].replace(\" n't\", \"n't\")\n",
    "            headent['name'] = headent['name'].replace(\" 're\", \"'re\")\n",
    "            headent['name'] = headent['name'].replace(\"( \", \"(\")\n",
    "            headent['name'] = headent['name'].replace(\" )\", \")\")\n",
    "            headent['name'] = headent['name'].replace('\" ', '\"')\n",
    "            headent['name'] = headent['name'].replace(' \"', '\"')\n",
    "            headent['name'] = headent['name'].replace(' ;', ';')\n",
    "            headent['name'] = headent['name'].replace(' :', ':')\n",
    "            val1['value']['start'] = para.find(headent['name'])\n",
    "            if val1['value']['start'] == -1:\n",
    "                notFound = notFound + 1\n",
    "                print(headent['name'], transferType(headent['type']))\n",
    "                print(para)\n",
    "                continue\n",
    "            val1['value']['end'] = val1['value']['start'] + len(headent['name'])\n",
    "            val1['value']['text'] = headent['name']\n",
    "            val1['value']['labels'] = transferType(headent['type'])\n",
    "            val1['id'] = id_generator(7)\n",
    "            val1['from_name'] = \"label\"\n",
    "            val1['to_name'] = \"text\"\n",
    "            val1['type'] = \"labels\"\n",
    "            comData['result'].append(val1)\n",
    "            foundLabesl[headent['name']] = val1['id']\n",
    "        else:\n",
    "            val1['id'] = foundLabesl[headent['name']]\n",
    "\n",
    "        val2 = {}\n",
    "        if tailent['name'] not in foundLabesl:\n",
    "            val2['value'] = {}\n",
    "            tailent['name'] = tailent['name'].replace(\" .\", \".\")\n",
    "            tailent['name'] = tailent['name'].replace(\" ,\", \",\")\n",
    "            tailent['name'] = tailent['name'].replace(\" – \", \"–\")\n",
    "            tailent['name'] = tailent['name'].replace(\" -\", \"–\")\n",
    "            tailent['name'] = tailent['name'].replace(\"– \", \"–\")\n",
    "            tailent['name'] = tailent['name'].replace(\" - \", \"-\")\n",
    "            tailent['name'] = tailent['name'].replace(\" -\", \"-\")\n",
    "            tailent['name'] = tailent['name'].replace(\"- \", \"-\")\n",
    "            tailent['name'] = tailent['name'].replace(\" '\", \"'\")\n",
    "            tailent['name'] = tailent['name'].replace(\" n't\", \"n't\")\n",
    "            tailent['name'] = tailent['name'].replace(\" 're\", \"'re\")\n",
    "            tailent['name'] = tailent['name'].replace(\"( \", \"(\")\n",
    "            tailent['name'] = tailent['name'].replace(\" )\", \")\")\n",
    "            tailent['name'] = tailent['name'].replace('\" ', '\"')\n",
    "            tailent['name'] = tailent['name'].replace(' \"', '\"')\n",
    "            tailent['name'] = tailent['name'].replace(' ;', ';')\n",
    "            tailent['name'] = tailent['name'].replace(' :', ':')\n",
    "            val2['value']['start'] = para.find(tailent['name'])\n",
    "            if val2['value']['start'] == -1:\n",
    "                notFound = notFound + 1\n",
    "                print(tailent['name'], transferType(tailent['type']))\n",
    "                print(para)\n",
    "                continue\n",
    "            val2['value']['end'] = val2['value']['start'] + len(tailent['name'])\n",
    "            val2['value']['text'] = tailent['name']\n",
    "            val2['value']['labels'] = transferType(tailent['type'])\n",
    "            val2['id'] = id_generator(7)\n",
    "            val2['from_name'] = \"label\"\n",
    "            val2['to_name'] = \"text\"\n",
    "            val2['type'] = \"labels\"\n",
    "            comData['result'].append(val2)\n",
    "            foundLabesl[tailent['name']] = val2['id']\n",
    "        else:\n",
    "            val2['id'] = foundLabesl[tailent['name']]\n",
    "\n",
    "        # val3 = {}\n",
    "        # if (val1['id'] in foundRelations and val2['id'] in foundRelations[val1['id']]) or (val2['id'] in foundRelations and val1['id'] in foundRelations[val2['id']]):\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     foundRelations[val1['id']] = val2['id']\n",
    "        #     foundRelations[val2['id']] = val1['id'] \n",
    "        #     val3['labels'] = [info[label['r']]]\n",
    "        #     val3['direction'] = \"bi\"\n",
    "        #     val3['from_id'] = val1['id']\n",
    "        #     val3['to_id'] = val2['id']\n",
    "        #     val3['type'] = \"relation\"\n",
    "        #     print(val3)\n",
    "        #     comData['result'].append(val3)\n",
    "        #     break\n",
    "            \n",
    "    completion = {}\n",
    "    completion['task_id'] =count\n",
    "    completion['user_id'] = 0\n",
    "    completion['data'] = json.dumps(comData)\n",
    "    completion['completed_at'] = 1616101190\n",
    "    completion['batch_id'] = 1\n",
    "    completion['was_skipped'] = 0\n",
    "    task['completion'] =  completion\n",
    "    count = count + 1\n",
    "    AllTasks.append(task)   \n",
    "        # break\n",
    "todump = {}\n",
    "todump[\"tasks\"] = AllTasks\n",
    "# print(json.dumps(todump))\n",
    "with open('OnlyEntitiesNew.json', 'w') as outfile:\n",
    "    json.dump(todump, outfile)\n",
    "print(count, \"Done\")\n",
    "print(notFound, \"Done\")\n",
    "# print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Never Gonna Give You Up ['Misc'] NotFound\nfoundLabesl Pos Never Gonna Give You Up 0\n\"Cry for Help\"is the title of the first single taken from British dance-pop singer Rick Astley's third studio album, Free. It was written by Rick Astley and Rob Fisher. The Andraé Crouch Choir provided backing vocals. Released as a single in January 1991,\"Cry for Help\"reached number seven on both the UK Singles Chart and the US Billboard Hot 100. It also reached number four in Canada and was a number-one hit on both the US and Canadian Adult Contemporary charts. The song's number-seven UK chart placing meant that Astley became the first male solo artist to have his first eight singles reach the British top 10. The song is a soul ballad, unlike Astley's other more dance-oriented hit singles such as\"Never Gon na Give You Up\". It was co-written by British singer Rob Fisher, formerly one half of the 1980s pop outfits Naked Eyes and Climie Fisher. To date, the song was Astley's last appearance in the top 10 in either the US or UK. The song has been sung by Rick Astley in duet with Soren Sko and covered by Thomas Anders (ex-Modern Talking).\nFatih Terim ['Person'] NotFound\nfoundLabesl Pos Fatih Terim 1\nFatih Terim, Commendatore OSSI, T.C, (born 4 September 1953) is a Turkish association football manager and former player. He is currently the manager of Galatasaray, a position he previously held three times. Terim has managed several clubs in Italy and Turkey, as well as the Turkish national football team, most recently from 2013 to 2017. In a survey conducted by the International Federation of Football History & Statistics (IFFHS) in 80 countries, he was placed among the best eight managers in the world, receiving his award at a ceremony held in Rothenburg, Germany, on 8 January 2001. Terim received a nomination for UEFA manager of the year 2008, and Eurosport named him the best coach at UEFA Euro 2008. In December 2008, he was ranked the seventh-best football manager in the world by World Soccer Magazine in 2008. His Turkish nickname is\"İmparator\", and his Italian nickname is\"Imperatore\". Both names mean\"emperor\".\nMuir Beach ['Location'] NotFound\nfoundLabesl Pos Muir Beach 1\nMuir Beach is a census designated place (CDP), unincorporated community, and beach that is located northwest of San Francisco in western Marin County, California, United States. It is named for John Muir. The population was 310 at the 2010 census. The community itself flanks the northwest side of the beach. Located about 2 miles (3   km) from the entrance to Muir Woods National Monument, the beach is about 1000 feet (305 m) long and 200 feet (61 m) wide, with coarse sand and several large boulders. Redwood Creek empties into the beach. There is a parking lot at the beach, which is accessible via a footbridge. The beach was formerly called Big Lagoon after a freshwater lagoon that was located where the parking lot is now. Damage from 20th century dairy farms interfered with the flow of the creek and the lagoon.\n14 nm ['Number'] NotFound\nfoundLabesl Pos 14 nm 0\nSkylake is the codename used by Intel for a processor microarchitecture that was launched in August 2015 succeeding the Broadwell microarchitecture. Skylake is a microarchitecture redesign using the same 14   nm manufacturing process technology as its predecessor, serving as a\"tock\"in Intel's\"tick-tock\"manufacturing and design model. According to Intel, the redesign brings greater CPU and GPU performance and reduced power consumption. Skylake CPUs share its microarchitecture with Kaby Lake, Coffee Lake and Cannon Lake CPUs. Skylake is the last Intel platform on which Windows earlier than Windows 10 will be officially supported by Microsoft, although enthusiast-created modifications exist that allow Windows 8.1 and earlier to continue to receive updates on later platforms. Some of the processors based on the Skylake microarchitecture are marketed as\"6th-generation Core\". On October 8, 2018, Intel announced new 9th gen Core X 98xx/99xx series CPUs, with the Core i9-9980XE Extreme Edition leading the launch.\n9.2 km ['Number'] NotFound\nfoundLabesl Pos 9.2 km 0\nDurgada is a rural village in Gollaprolu mandal, East Godavari district, Andhra Pradesh, India. The village was formerly known as durga ooda, durga vaahini. It is located north-east to the Pithapuram and [ Gollaprolu ]. The village is located 1.8 kilometers away from NH 214 and 3 kilometers away from NH 5. The nearest city (35   km) is Kakinada. The most convenient way of travel for the people in village is by train. Durgada has a railway gate halt. Other than this the nearest railway stations are Ravikampadu East Godavari (2.6   km) and Gollaprolu (9.2   km) and nearest railway junction is Samalkot. Nearest air strip is Madhurapudi, Rajahmundry (75   km) and nearest airport is Vishakapatnam (125   km) and nearest seaport is Kakinada Port.\n75 km ['Number'] NotFound\nfoundLabesl Pos 75 km 0\nDurgada is a rural village in Gollaprolu mandal, East Godavari district, Andhra Pradesh, India. The village was formerly known as durga ooda, durga vaahini. It is located north-east to the Pithapuram and [ Gollaprolu ]. The village is located 1.8 kilometers away from NH 214 and 3 kilometers away from NH 5. The nearest city (35   km) is Kakinada. The most convenient way of travel for the people in village is by train. Durgada has a railway gate halt. Other than this the nearest railway stations are Ravikampadu East Godavari (2.6   km) and Gollaprolu (9.2   km) and nearest railway junction is Samalkot. Nearest air strip is Madhurapudi, Rajahmundry (75   km) and nearest airport is Vishakapatnam (125   km) and nearest seaport is Kakinada Port.\n301 Done\n6 Done\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "notFound = 0\n",
    "def transferType(_type):\n",
    "    if _type == \"ORG\":\n",
    "        return [\"Organization\"]\n",
    "    elif _type == \"LOC\":\n",
    "        return [\"Location\"]\n",
    "    elif _type == \"TIME\":\n",
    "        return [\"Time\"]\n",
    "    elif _type == \"PER\":\n",
    "        return [\"Person\"]\n",
    "    elif _type == \"NUM\":\n",
    "        return [\"Number\"]\n",
    "    elif _type == \"MISC\":\n",
    "        return [\"Misc\"]\n",
    "\n",
    "# labelssDict = set()\n",
    "count = 0\n",
    "AllTasks = []\n",
    "for vertex in d:\n",
    "    AllSents = []\n",
    "    if count < 200:\n",
    "        count = count + 1\n",
    "        continue\n",
    "    if count > 300:\n",
    "        break\n",
    "    # else:\n",
    "        # print(count)\n",
    "    # print(vertex['vertexSet'])\n",
    "    # if len(vertex['labels']) <= 3:\n",
    "    for i,sent in enumerate(vertex['sents']):\n",
    "        # print(i,' '.join(sent))\n",
    "        s = ' '.join(sent)\n",
    "        s = s.replace('   ', ' ')\n",
    "        AllSents.append(s) \n",
    "    \n",
    "    if len(AllSents) > 10 or len(AllSents) < 3:\n",
    "        continue\n",
    "    para = ' '.join(AllSents) \n",
    "    para = para.replace(\" .\", \".\")\n",
    "    para = para.replace(\" ,\", \",\")\n",
    "    para = para.replace(\" - \", \"-\")\n",
    "    para = para.replace(\" -\", \"-\")\n",
    "    para = para.replace(\"- \", \"-\")\n",
    "    para = para.replace(\" – \", \"-\")\n",
    "    para = para.replace(\" –\", \"-\")\n",
    "    para = para.replace(\"– \", \"-\")\n",
    "    para = para.replace(\"–\", \"-\")\n",
    "    para = para.replace(\" '\", \"'\")\n",
    "    para = para.replace(\" n't\", \"n't\")\n",
    "    para = para.replace(\" 're\", \"'re\")\n",
    "    para = para.replace(\"( \", \"(\")\n",
    "    para = para.replace(\" )\", \")\")\n",
    "    para = para.replace('\" ', '\"')\n",
    "    para = para.replace(' \"', '\"')\n",
    "    para = para.replace(' ;', ';')\n",
    "    para = para.replace(' :', ':')\n",
    "    para = para.replace(' %', '%')\n",
    "    para = para.replace('% ', '%')\n",
    "    para = para.replace(' $', '$')\n",
    "    para = para.replace('$ ', '$')\n",
    "    para = para.replace('   ', ' ')    \n",
    "    para = re.sub(r' / ', '/', para)\n",
    "    # para = re.sub(r'  *', '&&&', para)\n",
    "    \n",
    "    # print(para)\n",
    "    task = {}\n",
    "    task['text'] = para\n",
    "    task['layout_id'] = 2\n",
    "    task['groundTruth'] = \" \"\n",
    "    task['format_type'] = 1\n",
    "    task['batch_id'] = 1\n",
    "    task['description'] = \" \"\n",
    "    task['id'] = count\n",
    "\n",
    "    comData = {}\n",
    "    comData['lead_time'] = 3.821\n",
    "    comData['result'] = []\n",
    "    comData['user'] = 0\n",
    "    # completion['created_at'] = 1616101190\n",
    "\n",
    "    foundLabesl = {}\n",
    "    foundLabeslCount = {}\n",
    "    foundRelations = {}\n",
    "\n",
    "    for vertexset in vertex['vertexSet']:\n",
    "        # headent = vertex['vertexSet'][label['h']][0]\n",
    "        # tailent = vertex['vertexSet'][label['t']][0]\n",
    "        # print(headent, tailent, label, info[label['r']])\n",
    "        # print(\"\\n\")\n",
    "        for headent in vertexset:\n",
    "            val1 = {}\n",
    "            val1['value'] = {}\n",
    "            headent['name'] = headent['name'].replace(\" .\", \".\")\n",
    "            headent['name'] = headent['name'].replace(\" ,\", \",\")\n",
    "            headent['name'] = headent['name'].replace(\" – \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" –\", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\"– \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\"–\", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" - \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" -\", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\"- \", \"-\")\n",
    "            headent['name'] = headent['name'].replace(\" '\", \"'\")\n",
    "            headent['name'] = headent['name'].replace(\" n't\", \"n't\")\n",
    "            headent['name'] = headent['name'].replace(\" 're\", \"'re\")\n",
    "            headent['name'] = headent['name'].replace(\"( \", \"(\")\n",
    "            headent['name'] = headent['name'].replace(\" )\", \")\")\n",
    "            headent['name'] = headent['name'].replace('\" ', '\"')\n",
    "            headent['name'] = headent['name'].replace(' \"', '\"')\n",
    "            headent['name'] = headent['name'].replace(' ;', ';')\n",
    "            headent['name'] = headent['name'].replace(' :', ':')\n",
    "            headent['name'] = headent['name'].replace(' %', '%')\n",
    "            headent['name'] = headent['name'].replace('% ', '%')\n",
    "            headent['name'] = headent['name'].replace('$ ', '$')\n",
    "            headent['name'] = headent['name'].replace(' $', '$')            \n",
    "            headent['name'] = headent['name'].replace('   ', ' ')            \n",
    "            headent['name'] = re.sub(r' / ', '/', headent['name'])\n",
    "            # headent['name'] = re.sub(r'  *', '&&&', headent['name'])\n",
    "            \n",
    "            if headent['name'] not in foundLabesl:        \n",
    "                foundLabesl[headent['name']] = 0\n",
    "            else:\n",
    "                foundLabesl[headent['name']] = foundLabesl[headent['name']] + 1\n",
    "            # print(\"foundLabesl Pos\",headent['name'],foundLabesl[headent['name']])\n",
    "            nextPos = foundLabesl[headent['name']]\n",
    "            val1['value']['start'] = para.find(headent['name'], nextPos)\n",
    "            if val1['value']['start'] == -1:\n",
    "                notFound = notFound + 1\n",
    "                print(headent['name'], transferType(headent['type']), \"NotFound\")\n",
    "                print(\"foundLabesl Pos\",headent['name'],foundLabesl[headent['name']])\n",
    "                print(para)\n",
    "                # continue\n",
    "                break\n",
    "            val1['value']['end'] = val1['value']['start'] + len(headent['name'])\n",
    "            val1['value']['text'] = headent['name']\n",
    "            val1['value']['labels'] = transferType(headent['type'])\n",
    "            val1['id'] = id_generator(7)\n",
    "            val1['from_name'] = \"label\"\n",
    "            val1['to_name'] = \"text\"\n",
    "            val1['type'] = \"labels\"\n",
    "            comData['result'].append(val1)\n",
    "       \n",
    "    completion = {}\n",
    "    completion['task_id'] =count\n",
    "    completion['user_id'] = 0\n",
    "    completion['data'] = json.dumps(comData)\n",
    "    completion['completed_at'] = 1616101190\n",
    "    completion['batch_id'] = 1\n",
    "    completion['was_skipped'] = 0\n",
    "    task['completion'] =  completion\n",
    "    count = count + 1\n",
    "    AllTasks.append(task)   \n",
    "    # break\n",
    "todump = {}\n",
    "todump[\"tasks\"] = AllTasks\n",
    "# print(json.dumps(todump))\n",
    "with open('OnlyEntitiesNew.json', 'w') as outfile:\n",
    "    json.dump(todump, outfile)\n",
    "print(count, \"Done\")\n",
    "print(notFound, \"Done\")\n",
    "# print(AllTasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}